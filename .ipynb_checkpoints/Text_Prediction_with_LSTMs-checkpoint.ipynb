{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQXdL6VmbLB_"
   },
   "outputs": [],
   "source": [
    "#Imports utilizados\n",
    "import sys\n",
    "import keras as K\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import *\n",
    "from keras import callbacks\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsVjPKlTcjKO"
   },
   "outputs": [],
   "source": [
    "#Nome do arquivo a ser aberto e atualizado pra lowercase\n",
    "filename = \"junglebook\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oaZ4jc_jl7y"
   },
   "outputs": [],
   "source": [
    "#Cria um diretório para salvar os checkpoints e o log de treino\n",
    "!mkdir \"jb\"\n",
    "!mkdir \"jk/log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0JengHnI4hx"
   },
   "outputs": [],
   "source": [
    "raw_text = ''.join(ch for ch in unicodedata.normalize('NFKD', raw_text) \n",
    "    if not unicodedata.combining(ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Z6v8cMTlhSd"
   },
   "outputs": [],
   "source": [
    "#Remove acentuação e pontuação de um texto\n",
    "import re\n",
    "raw_text = re.sub('[^a-zA-Z0-9 \\n\\.]', '', raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "uomhJyU6me1a",
    "outputId": "324442a8-8069-4d38-8232-d4e080810c4c"
   },
   "outputs": [],
   "source": [
    "#Exibe o texto após as modificações\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNZCRstYgSB-"
   },
   "outputs": [],
   "source": [
    "#Separa todas as letras do dataset/text, ou seja, cria um dicionário enumerando cada letra presente no texto\n",
    "#Para trabalharmos com essas letras precisamos transformá-las em números\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atTY0Nqggi8L"
   },
   "outputs": [],
   "source": [
    "#Número de caracteres\n",
    "n_chars = len(raw_text)\n",
    "#Número de caracteres únicos \n",
    "n_vocab = len(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pKOlbqUhVv6",
    "outputId": "d7df7ec4-a608-4be0-976a-8b4f898cf7b0"
   },
   "outputs": [],
   "source": [
    "print(\"Número de Caracteres: \",n_chars)\n",
    "print(\"Número de Caracteres únicos: \",n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EeGUO3Rhqp9",
    "outputId": "21158c20-13d2-4c41-d0e6-31a8d8398357"
   },
   "outputs": [],
   "source": [
    "#Tamanho da Sequência que procuramos\n",
    "#Nesse exemplo Utilizaremos uma sequência de 125, ou seja, usaremos 124 caracteres para prever o próximo\n",
    "#Seguimos o padrão de one-hot-encoding que prediz cada letra individualmente entre as outras presentes.\n",
    "seq_length = 125\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total de Padrões Apresentados: \", n_patterns)\n",
    "print(\"Utlizando um tamanho de Sequência igual a :\", seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyNRs_pqlUdW"
   },
   "outputs": [],
   "source": [
    "#Reshape da entrada pra treino\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "#Normalização\n",
    "X = X / float(n_vocab)\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNlkZNkAyIJy"
   },
   "outputs": [],
   "source": [
    "'''Usamos o train_test_split para separar 20% dos dados para teste, e assim\n",
    "aplicar uma variedade melhor de métricas '''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcGdrm5TlgW_"
   },
   "outputs": [],
   "source": [
    "#Criação do Modelo\n",
    "#Utilizamos uma rede razoavel de 2 camadas de 512 unidades de lstm para esse problema\n",
    "#Dropout simples de 0.2 e uma Camada Densa que calcula a saída no total de letras no dataset\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZE6STVEl_Fz"
   },
   "outputs": [],
   "source": [
    "#Callbacks utilizadas\n",
    "filepath=\"jb/{loss:.3f}.hdf5\"\n",
    "#Checkpoint salva a cade época os pesos de nosso modelo caso ele tenha tido um resultado melhor que o anterior\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min', restore_best_weights=True)\n",
    "#EarlyStopping comum, para o treino após 7 épocas sem melhoras na loss\n",
    "stop = callbacks.EarlyStopping(monitor='loss', patience=7)\n",
    "#CSVLogger, salva os dados/métricas de treino em um arquivo csv, usando um separador \",\"\n",
    "log = callbacks.CSVLogger(\"jb/log/jb.csv\", separator=\",\", append=True)\n",
    "callbacks_list = [checkpoint,stop,log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoJrXESKQlHe"
   },
   "outputs": [],
   "source": [
    "#Define a perplexidade, uma métrica não integrada ainda ao Keras, porém é facilmente inserida\n",
    "import keras.backend as K\n",
    "def perplexity(y_true, y_pred):\n",
    "    return K.exp(K.mean(K.categorical_crossentropy(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOoB7xaRJ_xd"
   },
   "outputs": [],
   "source": [
    "#Compila nosso modelo, nesse exemplo utilizamos o optimzer adam e as metricas extras de acurácia e perplexidade\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\",perplexity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64EWEhBKmXHo",
    "outputId": "7f4981c6-16c6-4f87-b58e-e9778fcb435f"
   },
   "outputs": [],
   "source": [
    "'''Inicia o treino de nosso modelo utiliando as ferramentes mostradas anteriormente, como:\n",
    "-Callbacks\n",
    "-Validation Data\n",
    "Para esse treino utilizamos 300 épocas e batch_size de 50 para mais eficiência.\n",
    "Dependendo do dataset, recomendo alterar esses valores para um treino mais rápido/simples ou o contrário =D\n",
    "'''\n",
    "history = model.fit(X_train, y_train, epochs=300, callbacks=callbacks_list, batch_size=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega os pesos do melhor checkpoint do modelo\n",
    "filename_w=\"jb/0.311.hdf5\"\n",
    "model.load_weights(filename_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kL4g6NozxGsy"
   },
   "outputs": [],
   "source": [
    "#Cria outra dicionário, inverso da operação anterior. Transforma os números em letras novamente\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayPJuJoUKeUo"
   },
   "outputs": [],
   "source": [
    "#Para gerarmos um texto, precisamos de um semente, e nisso escolhemos uma semente randomica de tamanho\n",
    "#igual ao que escolhemos anteriormente, nesse caso 125\n",
    "def pred_text(max_len):\n",
    "  #Seleciona um texto randômico\n",
    "  start = np.random.randint(0, len(dataX)-1) \n",
    "  pattern = dataX[start]\n",
    "  print (\"Semente randômica:\")\n",
    "  print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "  semente = \"\".join([int_to_char[value] for value in pattern])\n",
    "  #Prediz os caracteres num range escolhido\n",
    "  out = \"\"\n",
    "  for i in range(max_len):\n",
    "\t  x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\t  x = x / float(n_vocab)\n",
    "\t  prediction = model.predict(x, verbose=0)\n",
    "\t  index = np.argmax(prediction)\n",
    "\t  result = int_to_char[index]\n",
    "\t  seq_in = [int_to_char[value] for value in pattern]\n",
    "\t  out+=result\n",
    "\t  pattern.append(index)\n",
    "\t  pattern = pattern[1:len(pattern)]\n",
    "  return (semente + \" -> \" + out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHob1SdnK2EM",
    "outputId": "4c310904-cb4f-4c8c-adfb-82793bc60c2e"
   },
   "outputs": [],
   "source": [
    "#Chama a função pred_text para gerar um texto\n",
    "saida_1 = pred_text(2000)\n",
    "saida_2 = pred_text(1000)\n",
    "saida_3 = pred_text(700)\n",
    "saida_4 = pred_text(500)\n",
    "saida_5 = pred_text(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pR9eqy2yQj_",
    "outputId": "0c91aece-583b-44be-cb5c-c78550b0dbce"
   },
   "outputs": [],
   "source": [
    "print(\"1 Resultado: \",saida_1)\n",
    "print('------------------------') \n",
    "print(\"2 Resultado: \" ,saida_2)\n",
    "print('------------------------') \n",
    "print(\"3 Resultado: \",saida_3)\n",
    "print('------------------------') \n",
    "print(\"4 Resultado: \"  ,saida_4)\n",
    "print('------------------------') \n",
    "print(\"5 Resultado: \"  ,saida_4)\n",
    "print('------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPO-Ez9oaz85"
   },
   "outputs": [],
   "source": [
    "#Importa a biblioteca do Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOzQrm4abdHW"
   },
   "outputs": [],
   "source": [
    "#Lê o arquivo log que criamos utilizando a Callback CSVLogger\n",
    "df = pd.read_csv(\"jb/log/jb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiTjH2ckgfUy"
   },
   "outputs": [],
   "source": [
    "#Transforma a primeira coluna no número de épocas, caso tenha tido problemas com Desconexão ou algo do tipo\n",
    "for _ in range(len(df)):\n",
    "  df[\"epoch\"][_] = _+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "mNspfA28bxWe",
    "outputId": "6ba909e6-fe47-4311-de6d-c3a4f4f2e0d3"
   },
   "outputs": [],
   "source": [
    "#Faz um plot e comparação da acurácia para o conjunto de treino e teste\n",
    "df.plot(y=[\"accuracy\",\"val_accuracy\"],x='epoch', style=['g--','r--'], linewidth=2).set_facecolor('#ffff84')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "6V6_GG4Smz7a",
    "outputId": "6f5f4597-a1d2-4605-979b-e57cc9cdeb99"
   },
   "outputs": [],
   "source": [
    "#Faz um plot e comparação da perplexidade para o conjunto de treino e teste\n",
    "df.plot(y=[\"perplexity\",\"val_perplexity\"],x='epoch', style=['g--','r--'], linewidth=2).set_facecolor('#ffff84')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "J55L2Ic4m5FV",
    "outputId": "e5e60c8e-9b08-46ac-c0f4-ff7dccfe4a44"
   },
   "outputs": [],
   "source": [
    "#Faz um plot e comparação da perda para o conjunto de treino e teste\n",
    "df.plot(y=[\"loss\",\"val_loss\"],x='epoch', style=['g--','r--'], linewidth=2).set_facecolor('#ffff84')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text Prediction with LSTMs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
